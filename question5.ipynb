{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Familiarízate con la documentación scikit-multilearn en: http://scikit.ml/ Prueba los métodos ML disponibles pertenecientes a las dos categorías (transformación y adaptación) que hemos visto en teoría."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found existing installation: scikit-learn 0.24.1\n",
      "Uninstalling scikit-learn-0.24.1:\n",
      "  Successfully uninstalled scikit-learn-0.24.1\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Collecting scikit-learn==0.24.1\n",
      "  Downloading scikit-learn-0.24.1.tar.gz (7.4 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.4/7.4 MB\u001b[0m \u001b[31m35.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25h  Installing build dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n",
      "\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: joblib>=0.11 in ./multilabel_classification/lib/python3.10/site-packages (from scikit-learn==0.24.1) (1.2.0)\n",
      "Requirement already satisfied: scipy>=0.19.1 in ./multilabel_classification/lib/python3.10/site-packages (from scikit-learn==0.24.1) (1.10.0)\n",
      "Requirement already satisfied: numpy>=1.13.3 in ./multilabel_classification/lib/python3.10/site-packages (from scikit-learn==0.24.1) (1.24.1)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in ./multilabel_classification/lib/python3.10/site-packages (from scikit-learn==0.24.1) (3.1.0)\n",
      "Building wheels for collected packages: scikit-learn\n",
      "  Building wheel for scikit-learn (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for scikit-learn: filename=scikit_learn-0.24.1-cp310-cp310-linux_x86_64.whl size=22177693 sha256=ba98e606ff084c3f8ff7db3dad646cd4d8e82334fadc199530020b5c02caffdc\n",
      "  Stored in directory: /tmp/pip-ephem-wheel-cache-l1q327ak/wheels/e3/d6/1a/7d2b8f68ff52ac218b615e3b269d22af6df600d1b1c699c930\n",
      "Successfully built scikit-learn\n",
      "Installing collected packages: scikit-learn\n",
      "Successfully installed scikit-learn-0.24.1\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip uninstall scikit-learn -y\n",
    "%pip install --no-cache-dir scikit-learn==0.24.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "scene:train - exists, not redownloading\n",
      "scene:test - exists, not redownloading\n"
     ]
    }
   ],
   "source": [
    "from skmultilearn.dataset import load_dataset\n",
    "\n",
    "X_train, y_train, _, _ = load_dataset(set_name=\"scene\", variant=\"train\")\n",
    "X_test, y_test, _, _ = load_dataset(set_name=\"scene\", variant=\"test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transformation\n",
    "\n",
    "BINARY_RELEVANCE = 'BinaryRelevance'\n",
    "CLASSIFIER_CHAINS = 'Classifier Chains'\n",
    "LABEL_POWERSET = 'LabelPowerset'\n",
    "\n",
    "# Adaptation\n",
    "BRkNNaClassifier = 'BRkNNaClassifier'\n",
    "BRkNNbClassifier = 'BRkNNbClassifier'\n",
    "MLkNN = 'MLkNN'\n",
    "MLARAM = 'MLARAM'\n",
    "MLTSVM = 'MLTSVM'\n",
    "\n",
    "p = {BINARY_RELEVANCE: {},\n",
    "     CLASSIFIER_CHAINS: {},\n",
    "     LABEL_POWERSET: {},\n",
    "     BRkNNaClassifier: {},\n",
    "     BRkNNbClassifier: {},\n",
    "     MLkNN: {},\n",
    "     MLARAM: {},\n",
    "     MLTSVM: {}\n",
    "     }\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Binary Relevance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skmultilearn.problem_transform import BinaryRelevance\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "from car import get_description\n",
    "\n",
    "# initialize Binary Relevance multi-label classifier\n",
    "# with an SVM classifier\n",
    "# SVM in scikit only supports the X matrix in sparse representation\n",
    "\n",
    "classifier = BinaryRelevance(\n",
    "    classifier = SVC(),\n",
    "    require_dense = [False, True]\n",
    ")\n",
    "\n",
    "# train\n",
    "classifier.fit(X_train, y_train)\n",
    "\n",
    "# predict\n",
    "predictions = classifier.predict(X_test)\n",
    "p[BINARY_RELEVANCE] = predictions\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classifier Chains"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skmultilearn.problem_transform import ClassifierChain\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "# initialize Classifier Chain multi-label classifier\n",
    "# with an SVM classifier\n",
    "# SVM in scikit only supports the X matrix in sparse representation\n",
    "\n",
    "classifier = ClassifierChain(\n",
    "    classifier = SVC(),\n",
    "    require_dense = [False, True]\n",
    ")\n",
    "\n",
    "# train\n",
    "classifier.fit(X_train, y_train)\n",
    "\n",
    "# predict\n",
    "predictions = classifier.predict(X_test)\n",
    "p[CLASSIFIER_CHAINS] = predictions"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Label Powerset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skmultilearn.problem_transform import LabelPowerset\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import pandas as pd\n",
    "\n",
    "classifier = LabelPowerset(\n",
    "    classifier = RandomForestClassifier(n_estimators=100),\n",
    "    require_dense = [False, True]\n",
    ")\n",
    "\n",
    "# train\n",
    "classifier.fit(X_train, y_train)\n",
    "\n",
    "# predict\n",
    "predictions = classifier.predict(X_test)\n",
    "p[LABEL_POWERSET] = predictions"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Métodos de adaptación"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BRkNNaClassifier\n",
    "\n",
    "A Binary Relevance kNN classifier that assigns a label if at least half of the neighbors are also classified with the label\n",
    "\n",
    "\n",
    "@inproceedings{EleftheriosSpyromitros2008,\n",
    "   author = {Eleftherios Spyromitros, Grigorios Tsoumakas, Ioannis Vlahavas},\n",
    "   booktitle = {Proc. 5th Hellenic Conference on Artificial Intelligence (SETN 2008)},\n",
    "   title = {An Empirical Study of Lazy Multilabel Classification Algorithms},\n",
    "   year = {2008},\n",
    "   location = {Syros, Greece}\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/isa/Documents/python-projects/project-multilabel-classification/multilabel_classification/lib/python3.10/site-packages/sklearn/utils/validation.py:70: FutureWarning: Pass n_neighbors=3 as keyword args. From version 1.0 (renaming of 0.25) passing these as positional arguments will result in an error\n",
      "  warnings.warn(f\"Pass {args_msg} as keyword args. From version \"\n"
     ]
    }
   ],
   "source": [
    "from skmultilearn.adapt import BRkNNaClassifier\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "\n",
    "classifier = BRkNNaClassifier(k=3)\n",
    "classifier.k = 3\n",
    "# train\n",
    "classifier.fit(X_train, y_train)\n",
    "\n",
    "# predict\n",
    "predictions = classifier.predict(X_test)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BRkNNbClassifier\n",
    "\n",
    "@inproceedings{EleftheriosSpyromitros2008,\n",
    "   author = {Eleftherios Spyromitros, Grigorios Tsoumakas, Ioannis Vlahavas},\n",
    "   booktitle = {Proc. 5th Hellenic Conference on Artificial Intelligence (SETN 2008)},\n",
    "   title = {An Empirical Study of Lazy Multilabel Classification Algorithms},\n",
    "   year = {2008},\n",
    "   location = {Syros, Greece}\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skmultilearn.adapt import BRkNNbClassifier\n",
    "\n",
    "classifier = BRkNNbClassifier(k=3)\n",
    "\n",
    "# train\n",
    "classifier.fit(X_train, y_train)\n",
    "\n",
    "# predict\n",
    "predictions = classifier.predict(X_test)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multilabel k Nearest Neighbours (MLkNN)\n",
    "\n",
    "@article{zhang2007ml,\n",
    "  title={ML-KNN: A lazy learning approach to multi-label learning},\n",
    "  author={Zhang, Min-Ling and Zhou, Zhi-Hua},\n",
    "  journal={Pattern recognition},\n",
    "  volume={40},\n",
    "  number={7},\n",
    "  pages={2038--2048},\n",
    "  year={2007},\n",
    "  publisher={Elsevier}\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skmultilearn.adapt import MLkNN\n",
    "\n",
    "classifier = MLkNN(k=3)\n",
    "\n",
    "# train\n",
    "classifier.fit(X_train, y_train)\n",
    "\n",
    "# predict\n",
    "predictions = classifier.predict(X_test)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multi-label ARAM\n",
    "\n",
    "@INPROCEEDINGS{7395756,\n",
    "    author={F. Benites and E. Sapozhnikova},\n",
    "    booktitle={2015 IEEE International Conference on Data Mining Workshop (ICDMW)},\n",
    "    title={HARAM: A Hierarchical ARAM Neural Network for Large-Scale Text Classification},\n",
    "    year={2015},\n",
    "    volume={},\n",
    "    number={},\n",
    "    pages={847-854},\n",
    "    doi={10.1109/ICDMW.2015.14},\n",
    "    ISSN={2375-9259},\n",
    "    month={Nov},\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "max not found",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[25], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mskmultilearn\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39madapt\u001b[39;00m \u001b[39mimport\u001b[39;00m MLARAM\n\u001b[1;32m      3\u001b[0m classifier \u001b[39m=\u001b[39m MLARAM(threshold\u001b[39m=\u001b[39m\u001b[39m0.05\u001b[39m, vigilance\u001b[39m=\u001b[39m\u001b[39m0.95\u001b[39m)\n\u001b[0;32m----> 4\u001b[0m classifier\u001b[39m.\u001b[39;49mfit(X_train, y_train)\n\u001b[1;32m      5\u001b[0m prediction \u001b[39m=\u001b[39m classifier\u001b[39m.\u001b[39mpredict(X_test)\n",
      "File \u001b[0;32m~/Documents/python-projects/project-multilabel-classification/multilabel_classification/lib/python3.10/site-packages/skmultilearn/adapt/mlaram.py:165\u001b[0m, in \u001b[0;36mMLARAM.fit\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m    163\u001b[0m     y \u001b[39m=\u001b[39m numpy\u001b[39m.\u001b[39masarray(y)\n\u001b[1;32m    164\u001b[0m is_more_dimensional \u001b[39m=\u001b[39m \u001b[39mint\u001b[39m(\u001b[39mlen\u001b[39m(X[\u001b[39m0\u001b[39m]\u001b[39m.\u001b[39mshape) \u001b[39m!=\u001b[39m \u001b[39m1\u001b[39m)\n\u001b[0;32m--> 165\u001b[0m X \u001b[39m=\u001b[39m _normalize_input_space(X)\n\u001b[1;32m    167\u001b[0m y_0 \u001b[39m=\u001b[39m _get_label_vector(y, \u001b[39m0\u001b[39m)\n\u001b[1;32m    169\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mneurons) \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m:\n",
      "File \u001b[0;32m~/Documents/python-projects/project-multilabel-classification/multilabel_classification/lib/python3.10/site-packages/skmultilearn/adapt/mlaram.py:48\u001b[0m, in \u001b[0;36m_normalize_input_space\u001b[0;34m(X)\u001b[0m\n\u001b[1;32m     47\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_normalize_input_space\u001b[39m(X):\n\u001b[0;32m---> 48\u001b[0m     x_max \u001b[39m=\u001b[39m X\u001b[39m.\u001b[39;49mmax()\n\u001b[1;32m     49\u001b[0m     x_min \u001b[39m=\u001b[39m X\u001b[39m.\u001b[39mmin()\n\u001b[1;32m     50\u001b[0m     \u001b[39mif\u001b[39;00m x_max \u001b[39m<\u001b[39m \u001b[39m0\u001b[39m \u001b[39mor\u001b[39;00m x_max \u001b[39m>\u001b[39m \u001b[39m1\u001b[39m \u001b[39mor\u001b[39;00m x_min \u001b[39m<\u001b[39m \u001b[39m0\u001b[39m \u001b[39mor\u001b[39;00m x_min \u001b[39m>\u001b[39m \u001b[39m1\u001b[39m:\n",
      "File \u001b[0;32m~/Documents/python-projects/project-multilabel-classification/multilabel_classification/lib/python3.10/site-packages/scipy/sparse/_base.py:771\u001b[0m, in \u001b[0;36mspmatrix.__getattr__\u001b[0;34m(self, attr)\u001b[0m\n\u001b[1;32m    769\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mgetnnz()\n\u001b[1;32m    770\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 771\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mAttributeError\u001b[39;00m(attr \u001b[39m+\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m not found\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "\u001b[0;31mAttributeError\u001b[0m: max not found"
     ]
    }
   ],
   "source": [
    "from skmultilearn.adapt import MLARAM\n",
    "\n",
    "classifier = MLARAM(threshold=0.05, vigilance=0.95)\n",
    "classifier.fit(X_train, y_train)\n",
    "prediction = classifier.predict(X_test)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multilabel Twin Support Vector Machine\n",
    "\n",
    "@article{chen2016mltsvm,\n",
    "  title={MLTSVM: a novel twin support vector machine to multi-label learning},\n",
    "  author={Chen, Wei-Jie and Shao, Yuan-Hai and Li, Chun-Na and Deng, Nai-Yang},\n",
    "  journal={Pattern Recognition},\n",
    "  volume={52},\n",
    "  pages={61--74},\n",
    "  year={2016},\n",
    "  publisher={Elsevier}\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/isa/Documents/python-projects/project-multilabel-classification/multilabel_classification/lib/python3.10/site-packages/scipy/sparse/linalg/_dsolve/linsolve.py:394: SparseEfficiencyWarning: splu converted its input to CSC format\n",
      "  warn('splu converted its input to CSC format', SparseEfficiencyWarning)\n",
      "/home/isa/Documents/python-projects/project-multilabel-classification/multilabel_classification/lib/python3.10/site-packages/scipy/sparse/linalg/_dsolve/linsolve.py:285: SparseEfficiencyWarning: spsolve is more efficient when sparse b is in the CSC matrix format\n",
      "  warn('spsolve is more efficient when sparse b '\n"
     ]
    }
   ],
   "source": [
    "from skmultilearn.adapt import MLTSVM\n",
    "\n",
    "classifier = MLTSVM(c_k = 2**-1)\n",
    "\n",
    "# train\n",
    "classifier.fit(X_train, y_train)\n",
    "\n",
    "# predict\n",
    "predictions = classifier.predict(X_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "multilabel_classification",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6 (main, Nov 14 2022, 16:10:14) [GCC 11.3.0]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "b036a133365d9ca41a8cc0b1f1eca35c43e76eeb6280a2b349bb422c1705a195"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
